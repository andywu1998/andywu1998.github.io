# **基本信息**

- 姓名：Andy Wu
- 电话：189-1025-xxxx
- 邮箱：[wuliwei1998@qq.com](mailto:wuliwei1998@qq.com)
- 求职意向：后端研发工程师

# **教育经历**

## **北京信息科技大学-本科-计算机科学与技术 （2017.9～2021~7）**

- 在校期间热衷于程序设计竞赛，曾经获得国际大学生程序设计竞赛区域赛铜牌、蓝桥杯国家级二等奖。
- 绩点3.0/5.0
- 通过了大学英语四级考试
- 大三上学期开始进入互联网公司实习，先后在百度和字节跳动担任后端研发实习生。

# **工作经历**

## **百度-视觉技术部-通用架构组 后端研发实习生（2019.10～2020.4）**

- 组里的主要职责是视觉服务后端架构的开发和维护，协助部门内部各个算法组（人脸、ocr等）算法模型落地，为百度贴吧、网盘、小度音箱等厂内业务提供视觉技术支持。
- 工作内容
    - 参与百度视频中台网关部分的研发。

## **字节跳动-头条百科-数据侧 后端研发实习生（2020.4～2021.3）**

- **在头条百科部门主要负责百科数据的组，组里的核心目标是提升百科数据质量。**
- 主要负责数据统计看板，数据质量提升，以及数据仓库建设。

## Shopee- engineer infra-监控平台组-后端工程师（2021.7～至今）

- 组里的主要工作是开发与维护公司的监控平台系统，我主要参与时序数据库Victoria Metrics的研发工作。先后参与全公司范围内使用的短链接项目和时序数据库Victoria Metrics的研发。
- 参与全公司范围使用的短链接项目的开发
- 参与时序数据库Victoria Metrics的开发

# **荣誉奖项**

- 2019ACM-ICPC国际大学生程序设计竞赛 亚洲区域赛银川站 铜奖 2019.10
- 2019ACM-ICPC国际大学生程序设计竞赛 全国邀请赛（西安）铜奖 2019.5
- 第十届蓝桥杯C/C++程序设计 大学B组 全国二等奖 2019.5
- 北京信息科技大学第10届程序设计竞赛 一等奖 2019.11

# **项目经历**

## **字节跳动-头条百科-百科数据看板（2020.5～2021.2）**

### **项目介绍**

头条百科的日常运营和产品设计需要大量的数据进行支撑，为了方便产品和运营以及技术同学查看数据，我们开发了界面友好的数据看板，将百科的生产、消费、词条质量等数据进行可视化。

主要统计如下指标并将其可视化：

- 消费侧：搜索、曝光、点击pv和uv，词条按搜索pv从大到小排序，从垂类的维度统计等。
- 生产侧：操作记录统计、提交版本数、审核通过版本数统计。
- 词条侧：词条的状态（是否可编辑、是否可查看）统计，词条质量（摘要数、基本信息数、图片数、参考资料数等），词条名和义项名长度，摘要长度等。
- 特殊词条：敏感词、不宜下放词等展示。

从百科线上数据到可视化看板主要经历以下步骤：Mysql存放百科原始数据→字节跳动内部数据平台天级同步→hive→用spark处理原始数据→hive sql对数据进行统计→传到内部数据可视化平台→制作可视化图表。

### 主要职责

负责一部分数据的整个数据链路的工作，包括用spark处理数据、用hive进行统计以及可视化看板的制作。

## **字节跳动-头条百科-低质词条优化（2020.8~2021.3）**

### **项目介绍**

头条百科的词条创建和完善一方面靠机器自动处理简单任务，但大部分还是要靠奖励机制来吸引用户参与编辑和创建，在之前的任务下放主要靠人工在运营后台通过excel表下放任务，现在我们要通过机器把低质词条分类筛选出来，按搜索pv从大到小的顺序下放给任务。比如：无摘要图，摘要图尺寸小，无基本信息等。

数据处理处理流程大致如下：

通过Spark筛选出低质词条并对其进行归类导入到Hive表，如：无摘要图、摘要图尺寸小、无基本信息、摘要或正文包含无用信息等。将要下放的词条与不宜下放词条进行过滤之后形成任务表，通过Hive -> Kafka与线上服务对接进行任务下放。

### 主要职责

负责离线数据的处理，比如用Spark筛选地址词条，编写Hive SQL生成任务表，用公司内部的数据平台将Hive传送到Kafka。消费Kafka生成线上任务的流程由其他同事开发。

## **字节跳动-无效内链去除（2020.12~2021.1）**

### **项目介绍**

在一个百科词条里存在另外一个词条的链接，我们称之为【内链】，内链在用户编辑时添加。但是随着词条状态的变更，比如一个词条下架，那么原来指向这个词条的内链就会失效，我们称之为【无效内链】。这个项目要做的定时地将无效内链剔除。

通过Spark并行对全量词条进行json解析，可以得到一张内链表，关键列是from ID和to ID，from表示存在内链的词条ID，to表示内链所指向的词条ID。然后通过hive sql来得到每个词条内链所指向的词条的状态，从而筛选出来已经下架的to ID。通过内部数据平台将数据从hive送到Kafka，在golang服务消费，把无效内链去除。

### 主要职责

负责离线数据处理部分，用spark解析百科词条，将解析结果存到Hive。再用Hive筛选出来任务传送到Kafka，消费Kafka的部分由其他同事开发。

## Shopee-短链接项目

### 项目介绍

全公司范围使用的一个将长URL转换成短URL的项目，在内部的使用场景比如监控平台在内部IM发出的告警链接，在外部用于各种活动推广、分享时将长URL转换成短URL。

本项目是一个用golang原生库开发的http服务，用redis做缓存，TiDB做持久化存储，同时还有Click House对短链的访问数据进行解析。在大促期间QPS峰值为2w。

### 主要职责

负责核心模块short url（长链转短链，短链转长链的一个REST API服务）以及短链portal（通过调用short url来生成短链，同时提供一个可视化界面给用户生成短链以及显示历史记录）的开发。

## Shopee-时序数据库Victoria Metrics

### 项目介绍

Victoria Metrics（vm）是一个开源的高性能分布式时许数据库，是监控平台的核心组件之一。主要包括采集、写入、存储、查询、告警等模块，这些模块分开部署，有着很强的横向拓展能力。我们基于vm的社区版本开发了一系列用于提升vm可靠性的服务，同时修复社区版本存在的bug以及优化性能。

### 主要职责

定期查看并且将社区提的issue在我们的版本中修复。排查并修复SRE反馈的问题。开发kubernetes operator，推动查询组件vmselect容器化。
